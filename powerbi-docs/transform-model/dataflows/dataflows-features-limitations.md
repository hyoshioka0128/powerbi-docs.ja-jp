---
title: データフローの制限事項、制約、サポートされているコネクタと機能
description: データフローのすべての機能の概要
author: davidiseminger
ms.author: davidi
ms.reviewer: ''
ms.service: powerbi
ms.subservice: pbi-dataflows
ms.topic: how-to
ms.date: 04/02/2021
LocalizationGroup: Data from files
ms.openlocfilehash: a2478b5c1ba4a9d78078734d39e27a5d96e1e701
ms.sourcegitcommit: a3b1ccdd18ef705de960625a9715ad5bbc21b1b6
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 04/02/2021
ms.locfileid: "106227084"
---
# <a name="dataflows-limitations-and-considerations"></a>データフローの制限事項と考慮事項

以下のセクションで説明するように、作成、更新、容量管理に関して、ユーザーが留意する必要のあるデータフローの制限がいくつかあります。

## <a name="general-limitations"></a>一般的な制限事項

* 政府の環境にまたがる機能パリティは、[政府向け Power BI の機能の利用可能性](../../admin/service-govus-overview.md#power-bi-feature-availability)に関する記事に記載されています。
* 削除されたデータソースは、データフロー データソース ページからは削除されません。 これは問題のない動作であり、データフローの更新や編集には影響を与えません。 **ダイアグラム ビュー** では、削除されたデータ ソースはデータフローの系列として表示されます。
* 削除されたデータソースは、引き続き [設定] ページのゲートウェイ ドロップダウンに表示されます。
* "*深さ*" は、他のデータフローにリンクされたデータフローに相当します。 現在の最大の深さは 32 です。
* "*幅*" は、データフロー内のエンティティに相当します。
    * データフローには最適なエンティティの数に関するガイダンスや制限はありませんが、共有データフローには、エンティティあたり 2 時間、データフローあたり 3 時間の更新制限があります。 そのため、2 つのエンティティがあり、それぞれに 2 時間かかる場合は、それらを同じデータフローに配置しないでください。
    * Power BI Premium の場合は、ガイダンスや制限が特定の要件ではなく、個々のユース ケースによって決定されます。 Power BI Premium での唯一の制限は、データフローあたり 24 時間の更新です。
* 10 を超えるデータフローをワークスペースにまたがって更新するには、Power BI Premium サブスクリプションが必要です。
* PowerQuery の制限は、PowerQuery Online の使用制限に関する記事に記載されています。
* Power BI データフローでは、URL 引数でのグローバル変数の使用はサポートされていません。
* Multi-Geo は現在、サポートされていません。
* Vnet のサポートは、ゲートウェイを使用して実現されます。
* ゲートウェイ データ ソースで *計算されたエンティティ* を使用している場合、データ インジェストは、それらの計算とは異なるデータ ソースで実行する必要があります。 計算されたエンティティは、独自のマッシュ アップ手順内でデータを取り込むのではなく、インジェストにのみ使用されるエンティティに基づいて構築する必要があります。


## <a name="dataflow-authoring"></a>データフローの作成

データフローを作成するとき、ユーザーは次の点に注意する必要があります。

* データフローでの作成は、Power Query Online (PQO) 環境で行われます。[Power Query の制限事項](/power-query/power-query-online-limits)に関する記事で説明されている制限事項を参照してください。
データフローの作成は Power Query Online (PQO) 環境で行われるため、データフロー ワークロード構成に対して行われた更新は、更新にのみ反映され、作成エクスペリエンスには反映されません

* データフローは所有者のみが変更できます

* データフローは、"*マイ ワークスペース*" においては利用できません

* ゲートウェイ データ ソースを使用するデータフローにおいては、同じデータ ソースに対する複数の資格情報はサポートされません

* Web.Page コネクタを使用するには、ゲートウェイが必要です

## <a name="api-considerations"></a>API の考慮事項

サポートされている Dataflows REST API の詳細については、[REST API のリファレンス](/rest/api/power-bi/dataflows)を参照してください。 注意すべきいくつかの考慮事項を次に示します。

* データフローをエクスポートおよびインポートすると、そのデータフローに新しい ID が割り当てられます

* リンク テーブルが含まれるデータ フローをインポートしても、データフロー内の既存の参照は修正されません (これらのクエリは、データフローをインポートする前に手動で修正する必要があります)

* もともとインポート API を使用して作成されたデータフローは、*CreateOrOverwrite* パラメーターを使用して上書きできます

## <a name="dataflows-in-shared"></a>共有内のデータフロー

共有容量内のデータフローには制限があります。

* データフローを更新するときの共有でのタイムアウトは、テーブルごとに 2 時間、データフローごとに 3 時間です
* リンク テーブルは、共有データフロー内に作成することはできませんが、クエリで "*読み込み有効*" プロパティが無効になっている限り、データフロー内に存在することができます
* 計算テーブルを共有データフロー内に作成することはできません
* AutoML と Cognitive Services は、共有データフローでは使用できません
* 増分更新は、共有データフローでは機能しません

## <a name="dataflows-in-premium"></a>Premium でのデータフロー

Premium に存在するデータフローには、次の制限事項と考慮事項があります。

**更新とデータに関する考慮事項:**

* データフローを更新するときのタイムアウトは 24 時間です (テーブルとデータフローの区別はありません)

* 増分更新ポリシーから通常の更新に、またはその逆にデータフローを変更すると、すべてのデータが削除されます

* データフローのスキーマを変更すると、すべてのデータが削除されます

* データフローで Premium Per User (PPU) ライセンスを使用すると、PPU 環境からデータを移動するときにデータが消去されます

* Premium Per User (PPU) コンテキストでデータフローが更新されると、PPU 以外のユーザーにデータが表示されなくなります

**リンクおよび計算テーブル:**

* リンク テーブルは、32 参照の深さにまですることができます

* リンク テーブルの循環依存関係は許可されていません

* リンク テーブルを、オンプレミスのデータ ソースからデータを取得する通常のテーブルと結合することはできません

* データフローで別のクエリ (クエリ *B*) の計算に (たとえばクエリ *A* などの) クエリが使用されている場合、クエリ *B* が計算テーブルになります。 計算テーブルは、オンプレミスのソースを参照できません。


**コンピューティング エンジン:**

* コンピューティング エンジンを使用している間、データ インジェストの時間が最初に約 10% から 20% 増加します。

  * これは、コンピューティング エンジン上の最初のデータフローでの、データ ソースからのデータの読み取りにのみ該当します
  * ソース データフローを使用する以降のデータフローでは、同じペナルティは発生しません。

* 特定の操作によってのみ、リンク テーブルを通して、または計算テーブルとして使用される場合にのみ、コンピューティング エンジンが使用されます。 操作の完全な一覧については、[このブログ記事](http://petcu40.blogspot.com/2019/06/m-folding-in-enhanced-engine-of-power.html)を参照してください。


**容量管理:**

* 設計上、Premium Power BI 容量には、容量がメモリ不足の状態で実行されているときにワークロードをさまざまな方法で調整する内部のリソース マネージャーがあります。

  1. データフローの場合、この調整によって、使用可能な M コンテナーの数が減少します
  2. データフローのメモリは、データ サイズに合わせて適切にサイズ設定されたコンテナーを使用して 100% に設定でき、コンテナーの数はワークロードによって適切に管理されます

* コンテナーのおおよその数は、ワークロードに割り当てられたメモリの総量を、コンテナーに割り当てられたメモリの量で割ることによって確認できます

## <a name="dataflow-usage-in-datasets"></a>データセットでのデータフローの使用

* Power BI Desktop でデータセットを作成した後、それを Power BI サービスに発行する場合、データフローのデータ ソースに対して Power BI Desktop で使用されている資格情報が、データセットがサービスに発行されるときに使用される資格情報と同じであることを確認します。
  1. それらの資格情報が同じでないと、データセットの更新時に "*キーが見つからない*" というエラーが発生します


## <a name="adls-limitations"></a>ADLS の制限事項

* ADLS は、GCC、GCC High、DOD 環境では使用できません。 詳細については、「[米国政府顧客向け Power BI](../../admin/service-govus-overview.md)」を参照してください。
* ADLS Gen 2 API の変更のため、リソースの所有者として割り当てられている必要があります。
* Azure サブスクリプションの移行はサポートされていませんが、それを行う代わりの方法として次の 2 つがあります。
    * 最初のアプローチ: 移行の後、ユーザーはワークスペースをデタッチしてから、再アタッチできます。 テナント レベルのアカウントを使用している場合は、すべてのワークスペースをデタッチしてからテナント レベルでデタッチし、再アタッチする必要があります。 これは、すべてのデータフローの削除を避けたいお客様や、多数のワークスペースを保有しているお客様にとっては望ましくない場合があります。 
    * 2 番目のアプローチ: 前のアプローチを実行できない場合は、データベース内のサブスクリプション ID を変更するためのサポート リクエストを送信します。
* ADLS では、次の制限のために、ワークスペースの名前付けとデータフローの名前付けに関する記事の「[ディレクトリ名とファイル名](/rest/api/storageservices/naming-and-referencing-shares--directories--files--and-metadata)」セクションの一覧にあるほとんどの要素がサポートされていません。
    * Power BI は役に立たないエラーを返すか、またはこのプロセスの実行を許可しますが、更新は失敗します。 
* テナントにまたがる ADLS サブスクリプションはサポートされていません。 Power BI にアタッチされている ADLS は、Power BI が Azure Active Directory (Azure AD) に使用するのと同じ Azure テナントに属している必要があります。

## <a name="dataflow-data-types"></a>データフロー データ型

データフローでサポートされているデータ型は次のとおりです。

|マッシュアップ データ型   |データフロー データ型 |
|---------|---------|
|Time|Time|
|Date|Date|
|DateTime|DateTime|
|DateTimeZone|DateTimeOffset|
|論理|ブール型|
|テキスト|String|
|Any|String|
|Currency|Decimal|
|Int8   |Int64|
|Int16  |Int64|
|Int32  |Int64|
|Int64  |Int64|
|Double |Double|
|パーセント |Double|
|Single |Double|
|Decimal    |Double|
|数値 |Double|
|Duration   |サポートされていません|
|Binary |サポートされていません|
|機能   |サポートされていません|
|テーブル  |サポートされていません|
|List   |サポートされていません|
|Record |サポートされていません|
|Type   |サポートされていません|
|アクション |サポートされていません|
|なし   |サポートされていません|
|[Null]   |サポートされていません|


## <a name="next-steps"></a>次のステップ
データフローと Power BI の詳細については、以下の記事を参照してください。

* [データフローとセルフサービスのデータ準備の概要](dataflows-introduction-self-service.md)
* [データフローの作成](dataflows-create.md)
* [データフローの構成と使用](dataflows-configure-consume.md)
* [Azure Data Lake Gen 2 を使用するようにデータフロー ストレージを構成する](dataflows-azure-data-lake-storage-integration.md)
* [データフローの Premium 機能](dataflows-premium-features.md)
* [データフローを使用した AI](dataflows-machine-learning-integration.md)
* [データフローのベスト プラクティス](dataflows-best-practices.md)